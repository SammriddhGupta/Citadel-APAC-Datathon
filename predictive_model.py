# -*- coding: utf-8 -*-
"""Predictive Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JmB93hYkRIFg0SrPvpkvFqtDYOPzz4-i
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error
from google.colab import drive
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV

drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/APAC_2023_Datasets/processed/cleaned_crash.csv')

cat = ['make_cd', 'sex','special','region']
#replace NaN values with 0
data.travel_spd = data.travel_spd.fillna(0)
data = data.drop(columns=('weather2'))
for col in cat:
    data[col] = data[col].astype('category')
    data[col] = data[col].cat.codes

#replace na values with 0
data = data.dropna(0)

data.shape[0]

"""#Random Forest """

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import RFE

features = ['dvr_pres_ind', 'grade', 'make_cd', 'rdwy_alignment', 'travel_spd',
       'veh_type', 'veh_movement', 'veh_role', 'impact_point',
       'owner_driver', 'unit_num', 'unit_type', 'veh_position', 'age',
       'sex', 'inj_severity', 'collision_type', 'crash_year',
       'crash_month', 'time_of_day', 'illumination', 'hour_of_day',
       'location_type', 'intersect_type', 'max_severity_level',
       'weather1', 'relation_to_road', 'speed_limit',
       'special']
target = ['lat','lng']

print(len(features))

"""RFE Random Forest"""

random_seed = 42
# splitting data into train and test sets
train_dataset, test_dataset, train_labels, test_labels = train_test_split(data[features], data[target], test_size=0.1, random_state=random_seed)

model = RandomForestRegressor(n_estimators=100, random_state=random_seed)

# creating pipeline with model only
pipeline = Pipeline([
    ('model', model)
])

# fitting pipeline to train data
pipeline.fit(train_dataset, train_labels)

"""##RFE"""

random_seed = 42
# splitting data into train and test sets
train_dataset, test_dataset, train_labels, test_labels = train_test_split(data[features], data[target], test_size=0.1, random_state=random_seed)

# adding RFE to model
model = RandomForestRegressor(n_estimators=30, random_state=random_seed)

rfe = RFE(model, n_features_to_select=3)

# merging pipeline with RFE and model
pipeline = Pipeline([
    ('rfe', rfe),
    ('model', model)
])

# fitting pipeline to train data
pipeline.fit(train_dataset, train_labels)

import pickle
with open('randomforestmodel.pkl', 'wb') as f:
    pickle.dump(pipeline, f)

"""#Eval"""

#evaluation
test_predictions = pipeline.predict(test_dataset)
mse = mean_squared_error(test_labels, test_predictions)
mae = mean_absolute_error(test_labels, test_predictions)

print(f'Test MSE: {mse:.2f}')
print(f'Test MAE: {mae:.2f}')

# counting how many predictions are exactly equal to labels
correct_predictions = (test_predictions == test_labels).sum()

# calculating percentage of accurate predictions
accuracy = correct_predictions / len(test_dataset) * 100

print(accuracy)

plt.figure(figsize=(10, 10))
plt.xlabel('Actual Latitude')
plt.ylabel('Predicted Latitude')
plt.title('Actual vs Predicted Latitude')
plt.scatter(test_labels.lat, test_predictions[:, 0], c='b',alpha=0.1)
plt.legend()
plt.show()

plt.figure(figsize=(10, 10))
plt.xlabel('Actual Longitude')
plt.ylabel('Predicted Longitude')
plt.title('Actual vs Predicted Longitude')
plt.scatter(test_labels.lng, test_predictions[:, 1], c='b',alpha=0.1)
plt.legend()
plt.show()

plt.figure(figsize=(10, 10))
plt.scatter(test_labels.lat, test_labels.lng, c='r', label='Actual')
plt.scatter(test_predictions[:, 0], test_predictions[:, 1], c='b', label='Predicted',alpha=0.1)
#reduce alpha of points to see overlapping points
plt.legend()
plt.show()

from scipy.stats import gaussian_kde

#2d density plot of predictions
x = test_predictions[:, 0]
y = test_predictions[:, 1]
xy = np.vstack([x, y])
z = gaussian_kde(xy)(xy)

#plot heatmap
fig, ax = plt.subplots()
sc = ax.scatter(x, y, c=z, cmap='viridis', alpha=0.5)
ax.set_xlabel('Predicted Latitude')
ax.set_ylabel('Predicted Longitude')
ax.set_title('Heatmap of predictions')
cbar = fig.colorbar(sc)
cbar.ax.set_ylabel('Intensity')
plt.show()

errors = test_predictions - test_labels
plt.hist(errors, bins=20)
plt.xlabel('Prediction error')
plt.ylabel('Frequency')
plt.legend()
plt.title('Prediction error distribution')
plt.show()

import seaborn as sns

# get feature names and importances
feature_names = data[features].columns
feature_importances = pipeline.named_steps['model'].feature_importances_

# sort features by importance
sorted_idx = feature_importances.argsort()
sorted_names = feature_names[sorted_idx]
sorted_importances = feature_importances[sorted_idx]

# plot feature importance bar chart
plt.figure(figsize=(10,6))
sns.barplot(x=sorted_importances, y=sorted_names)
plt.title('Feature Importance of Random Forest Model')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

pred = pd.DataFrame(test_predictions, columns=['lat', 'lng'])